{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import  torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.],\n",
      "        [ 1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.ones(2,2),requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.],\n",
      "        [ 1.,  1.]])\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.data)\n",
    "print(x.grad)\n",
    "print(x.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.,  3.],\n",
      "        [ 3.,  3.]])\n"
     ]
    }
   ],
   "source": [
    "y = x+2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x00000000076A9400>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27.,  27.],\n",
      "        [ 27.,  27.]]) tensor(27.)\n"
     ]
    }
   ],
   "source": [
    "z = y * y *3\n",
    "out = z.mean()\n",
    "print(z,out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.5000,  4.5000],\n",
      "        [ 4.5000,  4.5000]])\n"
     ]
    }
   ],
   "source": [
    "# out.backward()\n",
    "print(x.grad)\n",
    "# dout / dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = Variable(torch.ones((2,2)),requires_grad = True)\n",
    "y = x + 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.],\n",
      "        [ 1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "y.backward(torch.ones(2,2),retain_graph = True)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.3593, -0.1669],\n",
      "        [ 1.6160,  1.7519]])\n"
     ]
    }
   ],
   "source": [
    "gradient = torch.randn(2, 2)\n",
    "\n",
    "y.backward(gradient=gradient)\n",
    "print(x.grad)\n",
    "torch.cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,data_size, hidden_size, output_size):\n",
    "        super(RNN,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        input_size = data_size + hidden_size\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size,hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size,output_size)\n",
    "        \n",
    "    def forward(self,data,last_hidden):\n",
    "        inputs = torch.cat((data,last_hidden),1)\n",
    "        hidden = self.i2h(inputs)\n",
    "        output = self.h2o(hidden)\n",
    "        \n",
    "        return hidden,output\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn = RNN(50,20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "batch_size = 10\n",
    "TIMESTEPS = 5\n",
    "batch = Variable(torch.randn(batch_size, 50))\n",
    "hidden = Variable(torch.zeros(batch_size, 20))\n",
    "target = Variable(torch.zeros(batch_size, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = 0 \n",
    "for t in range(TIMESTEPS):\n",
    "    hidden, output = rnn(batch,hidden)\n",
    "    loss += loss_fn(output,target)\n",
    "loss.backward()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.4866e-02, -7.4119e-02, -6.3060e-02,  ..., -3.4757e-02,\n",
      "          1.0739e-02,  1.1959e-02],\n",
      "        [ 5.9726e-02, -1.8990e-01,  1.5774e-02,  ..., -7.0121e-02,\n",
      "          4.1341e-02, -2.1392e-03],\n",
      "        [-8.9845e-02,  5.7795e-02, -8.4143e-02,  ...,  2.6410e-02,\n",
      "         -1.3987e-02, -4.2004e-03],\n",
      "        ...,\n",
      "        [-2.5783e-02,  1.2292e-01,  2.9126e-02,  ...,  9.8170e-02,\n",
      "         -7.4513e-03, -3.2644e-02],\n",
      "        [ 1.2227e-02, -5.5118e-02, -8.5919e-02,  ..., -3.1665e-02,\n",
      "          2.1021e-02,  9.3106e-03],\n",
      "        [-4.6562e-02,  9.9821e-02, -4.4699e-03,  ...,  3.6211e-02,\n",
      "         -4.0622e-02,  4.6574e-03]])\n"
     ]
    }
   ],
   "source": [
    "print(rnn.i2h.weight.grad.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MNISTConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTConvNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x = self.pool1(F.relu(self.conv1(inputs)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printnorm(self,input,output):\n",
    "        # input是将输入打包成的 tuple 的input\n",
    "        # 输出是一个 Variable. output.data 是我们感兴趣的 Tensor\n",
    "        print('Inside ' + self.__class__.__name__ + ' forward')\n",
    "        print('')\n",
    "        print('input: ', type(input))\n",
    "        print('input[0]: ', type(input[0]))\n",
    "        print('output: ', type(output))\n",
    "        print('')\n",
    "        print('input size:', input[0].size())\n",
    "        print('output size:', output.data.size())\n",
    "        print('output norm:', output.data.norm())    \n",
    "\n",
    "        \n",
    "def printgradnorm(self,grad_input,grad_output):\n",
    "        print('Inside ' + self.__class__.__name__ + ' backward')\n",
    "        print('Inside class:' + self.__class__.__name__)\n",
    "        print('')\n",
    "        print('grad_input: ', type(grad_input))\n",
    "        print('grad_input[0]: ', type(grad_input[0]))\n",
    "        print('grad_output: ', type(grad_output))\n",
    "        print('grad_output[0]: ', type(grad_output[0]))\n",
    "        print('')\n",
    "        print('grad_input size:', grad_input[0].size())\n",
    "        print('grad_output size:', grad_output[0].size())\n",
    "        print('grad_input norm:', grad_input[0].data.norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTConvNet(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = MNISTConvNet()\n",
    "net.conv2.register_forward_hook(printnorm)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Conv2d forward\n",
      "\n",
      "input:  <class 'tuple'>\n",
      "input[0]:  <class 'torch.Tensor'>\n",
      "output:  <class 'torch.Tensor'>\n",
      "\n",
      "input size: torch.Size([1, 10, 12, 12])\n",
      "output size: torch.Size([1, 20, 8, 8])\n",
      "output norm: tensor(14.8274)\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "net.conv2.register_backward_hook(printgradnorm)\n",
    "input = Variable(torch.randn(1, 1, 28, 28))\n",
    "out = net(input)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Conv2d backward\n",
      "Inside class:Conv2d\n",
      "\n",
      "grad_input:  <class 'tuple'>\n",
      "grad_input[0]:  <class 'torch.Tensor'>\n",
      "grad_output:  <class 'tuple'>\n",
      "grad_output[0]:  <class 'torch.Tensor'>\n",
      "\n",
      "grad_input size: torch.Size([1, 10, 12, 12])\n",
      "grad_output size: torch.Size([1, 20, 8, 8])\n",
      "grad_input norm: tensor(0.1266)\n",
      "Inside Conv2d backward\n",
      "Inside class:Conv2d\n",
      "\n",
      "grad_input:  <class 'tuple'>\n",
      "grad_input[0]:  <class 'torch.Tensor'>\n",
      "grad_output:  <class 'tuple'>\n",
      "grad_output[0]:  <class 'torch.Tensor'>\n",
      "\n",
      "grad_input size: torch.Size([1, 10, 12, 12])\n",
      "grad_output size: torch.Size([1, 20, 8, 8])\n",
      "grad_input norm: tensor(0.1266)\n"
     ]
    }
   ],
   "source": [
    "target = Variable(torch.LongTensor([3]))\n",
    "loss_fn = nn.CrossEntropyLoss()  # LogSoftmax + ClassNLL Loss\n",
    "err = loss_fn(out, target)\n",
    "err.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3118)\n"
     ]
    }
   ],
   "source": [
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(net.conv1.weight.grad.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8076)\n"
     ]
    }
   ],
   "source": [
    "print(net.conv1.weight.data.norm()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0008, -0.0816,  0.0310,  0.1686, -0.0389],\n",
      "          [-0.0050, -0.0788,  0.0251,  0.0109,  0.0434],\n",
      "          [ 0.0835,  0.1897, -0.1687, -0.0181,  0.1255],\n",
      "          [ 0.1062,  0.0422, -0.1908,  0.0672, -0.0682],\n",
      "          [-0.0082, -0.1798,  0.0592,  0.0936,  0.1094]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1595, -0.1299,  0.1768, -0.1956,  0.1226],\n",
      "          [ 0.0398,  0.0983, -0.0658,  0.0003,  0.1824],\n",
      "          [ 0.0979,  0.1665,  0.1380,  0.0124,  0.0347],\n",
      "          [-0.1168,  0.1872,  0.0698,  0.0945,  0.1028],\n",
      "          [ 0.0536,  0.0379,  0.0934,  0.1520, -0.1947]]],\n",
      "\n",
      "\n",
      "        [[[-0.0401, -0.0922, -0.0193,  0.0570,  0.1690],\n",
      "          [ 0.1249, -0.1095, -0.1972, -0.0259, -0.0158],\n",
      "          [-0.1746, -0.1906,  0.0617,  0.0348, -0.1981],\n",
      "          [ 0.0776, -0.1885, -0.0495, -0.1041, -0.1412],\n",
      "          [ 0.1412,  0.1706, -0.1284, -0.1279,  0.1303]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1859,  0.0130,  0.0675, -0.0208,  0.0736],\n",
      "          [-0.0456, -0.1183,  0.1461, -0.1985, -0.0613],\n",
      "          [ 0.0655,  0.0824, -0.0145,  0.1020, -0.1782],\n",
      "          [-0.1959,  0.1042, -0.1093, -0.1871, -0.1893],\n",
      "          [-0.1092,  0.0394,  0.1971, -0.1618, -0.0482]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0134, -0.1888,  0.0152,  0.1167, -0.0782],\n",
      "          [ 0.1610,  0.1964, -0.0160, -0.0862, -0.1836],\n",
      "          [ 0.0767, -0.0572,  0.0457,  0.1394,  0.0597],\n",
      "          [-0.1100,  0.0948,  0.1545, -0.1776, -0.0914],\n",
      "          [ 0.0504, -0.1295,  0.0270, -0.0351,  0.1593]]],\n",
      "\n",
      "\n",
      "        [[[-0.1823,  0.0928,  0.0247,  0.0239,  0.0472],\n",
      "          [ 0.0167,  0.0834, -0.1425, -0.1550, -0.1337],\n",
      "          [ 0.0418,  0.0081, -0.0268, -0.1149,  0.1660],\n",
      "          [-0.1742,  0.0243, -0.1967, -0.1135, -0.0004],\n",
      "          [-0.0883, -0.0954,  0.0620,  0.1083,  0.1040]]],\n",
      "\n",
      "\n",
      "        [[[-0.1404,  0.0277, -0.0578, -0.0181, -0.1743],\n",
      "          [-0.0949, -0.0365,  0.0261, -0.0703, -0.0047],\n",
      "          [-0.0252,  0.0084,  0.1685, -0.1797, -0.0072],\n",
      "          [ 0.1323,  0.0595,  0.0526,  0.1341,  0.0699],\n",
      "          [ 0.1020,  0.0741,  0.1483,  0.0947, -0.0308]]],\n",
      "\n",
      "\n",
      "        [[[-0.0605,  0.0399,  0.0237,  0.1616,  0.0773],\n",
      "          [ 0.1215,  0.1734,  0.1446, -0.1844,  0.1785],\n",
      "          [-0.0610, -0.1980,  0.1013, -0.1524, -0.1078],\n",
      "          [-0.1897, -0.1652,  0.1482, -0.0049, -0.1309],\n",
      "          [ 0.0171, -0.0763, -0.0590, -0.0504, -0.1040]]],\n",
      "\n",
      "\n",
      "        [[[-0.1779, -0.0668,  0.0375, -0.0111, -0.1978],\n",
      "          [-0.1612, -0.0481,  0.0488, -0.0473, -0.1645],\n",
      "          [ 0.1928, -0.1751, -0.0547,  0.1675,  0.0774],\n",
      "          [ 0.1332, -0.1369, -0.0207,  0.0595,  0.0685],\n",
      "          [ 0.0005,  0.0405, -0.1039, -0.1129, -0.0715]]],\n",
      "\n",
      "\n",
      "        [[[-0.1052,  0.0761,  0.0476, -0.1597, -0.1654],\n",
      "          [-0.0849,  0.1134, -0.0178,  0.0849, -0.1832],\n",
      "          [-0.0241,  0.1495,  0.1144,  0.1384,  0.0940],\n",
      "          [-0.0515,  0.0582, -0.1913, -0.1197,  0.0269],\n",
      "          [-0.0653,  0.0970,  0.0502, -0.1883,  0.0835]]]])\n"
     ]
    }
   ],
   "source": [
    "print(net.conv1.weight.data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
