{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import  torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.],\n",
      "        [ 1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.ones(2,2),requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.],\n",
      "        [ 1.,  1.]])\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.data)\n",
    "print(x.grad)\n",
    "print(x.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.,  3.],\n",
      "        [ 3.,  3.]])\n"
     ]
    }
   ],
   "source": [
    "y = x+2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x00000000076A9400>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27.,  27.],\n",
      "        [ 27.,  27.]]) tensor(27.)\n"
     ]
    }
   ],
   "source": [
    "z = y * y *3\n",
    "out = z.mean()\n",
    "print(z,out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.5000,  4.5000],\n",
      "        [ 4.5000,  4.5000]])\n"
     ]
    }
   ],
   "source": [
    "# out.backward()\n",
    "print(x.grad)\n",
    "# dout / dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(torch.ones((2,2)),requires_grad = True)\n",
    "y = x + 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.],\n",
      "        [ 1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "y.backward(torch.ones(2,2),retain_graph = True)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.3593, -0.1669],\n",
      "        [ 1.6160,  1.7519]])\n"
     ]
    }
   ],
   "source": [
    "gradient = torch.randn(2, 2)\n",
    "\n",
    "y.backward(gradient=gradient)\n",
    "print(x.grad)\n",
    "torch.cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,data_size, hidden_size, output_size):\n",
    "        super(RNN,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        input_size = data_size + hidden_size\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size,hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size,output_size)\n",
    "        \n",
    "    def forward(self,data,last_hidden):\n",
    "        inputs = torch.cat((data,last_hidden),1)\n",
    "        hidden = self.i2h(inputs)\n",
    "        output = self.h2o(hidden)\n",
    "        \n",
    "        return hidden,output\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn = RNN(50,20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "batch_size = 10\n",
    "TIMESTEPS = 5\n",
    "batch = Variable(torch.randn(batch_size, 50))\n",
    "hidden = Variable(torch.zeros(batch_size, 20))\n",
    "target = Variable(torch.zeros(batch_size, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0 \n",
    "for t in range(TIMESTEPS):\n",
    "    hidden, output = rnn(batch,hidden)\n",
    "    loss += loss_fn(output,target)\n",
    "loss.backward()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.4866e-02, -7.4119e-02, -6.3060e-02,  ..., -3.4757e-02,\n",
      "          1.0739e-02,  1.1959e-02],\n",
      "        [ 5.9726e-02, -1.8990e-01,  1.5774e-02,  ..., -7.0121e-02,\n",
      "          4.1341e-02, -2.1392e-03],\n",
      "        [-8.9845e-02,  5.7795e-02, -8.4143e-02,  ...,  2.6410e-02,\n",
      "         -1.3987e-02, -4.2004e-03],\n",
      "        ...,\n",
      "        [-2.5783e-02,  1.2292e-01,  2.9126e-02,  ...,  9.8170e-02,\n",
      "         -7.4513e-03, -3.2644e-02],\n",
      "        [ 1.2227e-02, -5.5118e-02, -8.5919e-02,  ..., -3.1665e-02,\n",
      "          2.1021e-02,  9.3106e-03],\n",
      "        [-4.6562e-02,  9.9821e-02, -4.4699e-03,  ...,  3.6211e-02,\n",
      "         -4.0622e-02,  4.6574e-03]])\n"
     ]
    }
   ],
   "source": [
    "print(rnn.i2h.weight.grad.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTConvNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x = self.pool1(F.relu(self.conv1(inputs)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printnorm(self,input,output):\n",
    "        # input是将输入打包成的 tuple 的input\n",
    "        # 输出是一个 Variable. output.data 是我们感兴趣的 Tensor\n",
    "        print('Inside ' + self.__class__.__name__ + ' forward')\n",
    "        print('')\n",
    "        print('input: ', type(input))\n",
    "        print('input[0]: ', type(input[0]))\n",
    "        print('output: ', type(output))\n",
    "        print('')\n",
    "        print('input size:', input[0].size())\n",
    "        print('output size:', output.data.size())\n",
    "        print('output norm:', output.data.norm())    \n",
    "\n",
    "        \n",
    "def printgradnorm(self,grad_input,grad_output):\n",
    "        print('Inside ' + self.__class__.__name__ + ' backward')\n",
    "        print('Inside class:' + self.__class__.__name__)\n",
    "        print('')\n",
    "        print('grad_input: ', type(grad_input))\n",
    "        print('grad_input[0]: ', type(grad_input[0]))\n",
    "        print('grad_output: ', type(grad_output))\n",
    "        print('grad_output[0]: ', type(grad_output[0]))\n",
    "        print('')\n",
    "        print('grad_input size:', grad_input[0].size())\n",
    "        print('grad_output size:', grad_output[0].size())\n",
    "        print('grad_input norm:', grad_input[0].data.norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTConvNet(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = MNISTConvNet()\n",
    "net.conv2.register_forward_hook(printnorm)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Conv2d forward\n",
      "\n",
      "input:  <class 'tuple'>\n",
      "input[0]:  <class 'torch.Tensor'>\n",
      "output:  <class 'torch.Tensor'>\n",
      "\n",
      "input size: torch.Size([1, 10, 12, 12])\n",
      "output size: torch.Size([1, 20, 8, 8])\n",
      "output norm: tensor(14.8274)\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "net.conv2.register_backward_hook(printgradnorm)\n",
    "input = Variable(torch.randn(1, 1, 28, 28))\n",
    "out = net(input)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Conv2d backward\n",
      "Inside class:Conv2d\n",
      "\n",
      "grad_input:  <class 'tuple'>\n",
      "grad_input[0]:  <class 'torch.Tensor'>\n",
      "grad_output:  <class 'tuple'>\n",
      "grad_output[0]:  <class 'torch.Tensor'>\n",
      "\n",
      "grad_input size: torch.Size([1, 10, 12, 12])\n",
      "grad_output size: torch.Size([1, 20, 8, 8])\n",
      "grad_input norm: tensor(0.1266)\n",
      "Inside Conv2d backward\n",
      "Inside class:Conv2d\n",
      "\n",
      "grad_input:  <class 'tuple'>\n",
      "grad_input[0]:  <class 'torch.Tensor'>\n",
      "grad_output:  <class 'tuple'>\n",
      "grad_output[0]:  <class 'torch.Tensor'>\n",
      "\n",
      "grad_input size: torch.Size([1, 10, 12, 12])\n",
      "grad_output size: torch.Size([1, 20, 8, 8])\n",
      "grad_input norm: tensor(0.1266)\n"
     ]
    }
   ],
   "source": [
    "target = Variable(torch.LongTensor([3]))\n",
    "loss_fn = nn.CrossEntropyLoss()  # LogSoftmax + ClassNLL Loss\n",
    "err = loss_fn(out, target)\n",
    "err.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3118)\n"
     ]
    }
   ],
   "source": [
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0478, -0.0476, -0.0388, -0.0287,  0.0257],\n",
      "          [ 0.0099,  0.0529,  0.0834,  0.0067, -0.0230],\n",
      "          [-0.0046, -0.0345, -0.0473,  0.0099, -0.0944],\n",
      "          [-0.0271,  0.0146,  0.0570,  0.0069,  0.0040],\n",
      "          [-0.0302,  0.0090, -0.0464, -0.0834, -0.0756]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0821, -0.0441, -0.1088,  0.0549, -0.0238],\n",
      "          [ 0.0425, -0.0141, -0.0131,  0.0661, -0.1001],\n",
      "          [-0.0532,  0.0104,  0.0697, -0.0445,  0.0013],\n",
      "          [ 0.0152,  0.0056,  0.0217,  0.0595,  0.0443],\n",
      "          [ 0.0113,  0.0292,  0.0647,  0.0437, -0.0347]]],\n",
      "\n",
      "\n",
      "        [[[-0.0068, -0.0762,  0.0715,  0.0218,  0.0290],\n",
      "          [-0.0352,  0.0114,  0.1271,  0.0534,  0.0514],\n",
      "          [-0.0367,  0.0262, -0.0040,  0.0034, -0.0705],\n",
      "          [ 0.0463,  0.0079,  0.0563, -0.0274,  0.0233],\n",
      "          [ 0.0416,  0.0064, -0.0361,  0.0291, -0.0573]]],\n",
      "\n",
      "\n",
      "        [[[-0.0098,  0.0478,  0.0428, -0.0507,  0.0298],\n",
      "          [ 0.0033, -0.0395,  0.0012,  0.0803, -0.0116],\n",
      "          [ 0.0042,  0.0144, -0.0182, -0.0488, -0.0354],\n",
      "          [ 0.0412, -0.0202,  0.0452, -0.0419, -0.1218],\n",
      "          [ 0.1029, -0.0511,  0.0413, -0.0564, -0.0504]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0794, -0.0423,  0.0414, -0.0352,  0.0807],\n",
      "          [-0.0046,  0.0361, -0.0159,  0.0232,  0.0421],\n",
      "          [ 0.0324, -0.0624, -0.0853,  0.0249, -0.0294],\n",
      "          [-0.1167,  0.0707,  0.0846,  0.0043,  0.0887],\n",
      "          [ 0.0137, -0.0387, -0.0037, -0.0429, -0.0281]]],\n",
      "\n",
      "\n",
      "        [[[-0.0118, -0.0187,  0.0312, -0.0468, -0.0441],\n",
      "          [-0.0754, -0.0492, -0.0409,  0.0092, -0.0135],\n",
      "          [-0.0296, -0.0177, -0.0075, -0.0652, -0.0097],\n",
      "          [-0.0025, -0.0415, -0.0797,  0.0432,  0.0260],\n",
      "          [ 0.0282, -0.0028,  0.0154,  0.0329, -0.0525]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0876, -0.0402, -0.0384, -0.0406,  0.0576],\n",
      "          [ 0.0280,  0.0248, -0.0272, -0.0141,  0.0905],\n",
      "          [ 0.0427, -0.0483,  0.0162, -0.0285, -0.0026],\n",
      "          [ 0.0123, -0.0766, -0.0596,  0.0103,  0.0495],\n",
      "          [ 0.0498, -0.0534,  0.0378, -0.0008, -0.0048]]],\n",
      "\n",
      "\n",
      "        [[[-0.0773,  0.0118,  0.0126, -0.0141, -0.0281],\n",
      "          [ 0.0040,  0.1233,  0.0816, -0.0508,  0.0690],\n",
      "          [ 0.0327, -0.0206, -0.0643, -0.0371,  0.0219],\n",
      "          [ 0.1010,  0.0502, -0.0178,  0.0300,  0.0202],\n",
      "          [-0.0701, -0.0100,  0.0342, -0.0154, -0.0182]]],\n",
      "\n",
      "\n",
      "        [[[-0.0700,  0.0016,  0.0130,  0.0626,  0.0004],\n",
      "          [-0.0162, -0.0636,  0.0913,  0.0495, -0.0270],\n",
      "          [ 0.0057, -0.0904,  0.0742, -0.0396,  0.0785],\n",
      "          [-0.0036,  0.0013,  0.0242,  0.0501, -0.0102],\n",
      "          [-0.0047,  0.0437, -0.0550,  0.0451, -0.0484]]],\n",
      "\n",
      "\n",
      "        [[[-0.0189,  0.1060,  0.0126,  0.0200,  0.0316],\n",
      "          [ 0.0194,  0.0339, -0.0642,  0.0228, -0.0513],\n",
      "          [-0.0171,  0.0326,  0.0080,  0.0475,  0.1247],\n",
      "          [-0.0014,  0.0681, -0.0419, -0.0270, -0.0316],\n",
      "          [ 0.0329,  0.0349, -0.0674, -0.0684,  0.0839]]]])\n"
     ]
    }
   ],
   "source": [
    "print(net.conv1.weight.grad.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8076)\n"
     ]
    }
   ],
   "source": [
    "print(net.conv1.weight.data.norm()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.1955,  0.0979,  0.1875, -0.0746, -0.1249],\n",
      "          [ 0.1798, -0.0377,  0.1087, -0.0187,  0.1748],\n",
      "          [-0.0079,  0.1175, -0.1350,  0.0420, -0.1649],\n",
      "          [-0.1567, -0.1062,  0.0849,  0.1565, -0.1799],\n",
      "          [ 0.0658,  0.0009, -0.0490,  0.1356,  0.0889]]],\n",
      "\n",
      "\n",
      "        [[[-0.0659,  0.1521,  0.0675,  0.0416,  0.0227],\n",
      "          [-0.0665, -0.0617,  0.1824,  0.0383,  0.0557],\n",
      "          [-0.1604, -0.0686,  0.0936,  0.0443,  0.1796],\n",
      "          [-0.1764,  0.1220,  0.1382, -0.0644,  0.0217],\n",
      "          [ 0.0408, -0.1252, -0.1183,  0.1791,  0.0248]]],\n",
      "\n",
      "\n",
      "        [[[-0.1609, -0.0675, -0.1635,  0.1330,  0.0171],\n",
      "          [ 0.1561, -0.1228, -0.1146, -0.0904, -0.1023],\n",
      "          [ 0.1564, -0.1949, -0.1905,  0.0228,  0.0378],\n",
      "          [ 0.1854, -0.1842, -0.1744,  0.1561, -0.0660],\n",
      "          [-0.1391,  0.0213,  0.0758,  0.1615,  0.0583]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1589,  0.0013,  0.1320,  0.0520, -0.1452],\n",
      "          [-0.0677, -0.1662, -0.1133, -0.1928,  0.0704],\n",
      "          [-0.0646, -0.1733, -0.1008, -0.0761,  0.1007],\n",
      "          [ 0.0191,  0.0058,  0.0106,  0.1587,  0.0345],\n",
      "          [-0.1959, -0.0558,  0.1850, -0.1727, -0.0375]]],\n",
      "\n",
      "\n",
      "        [[[-0.0787,  0.1007,  0.1125,  0.1779, -0.1101],\n",
      "          [ 0.0398, -0.1050,  0.0691,  0.0886, -0.0993],\n",
      "          [ 0.0040, -0.0503,  0.1384, -0.1329,  0.1322],\n",
      "          [-0.0083, -0.1655,  0.1451, -0.1992, -0.1036],\n",
      "          [-0.1149, -0.1559, -0.1257, -0.0231,  0.1398]]],\n",
      "\n",
      "\n",
      "        [[[-0.0818, -0.1944, -0.1146, -0.1796, -0.1735],\n",
      "          [ 0.0692,  0.1280,  0.0813, -0.0263, -0.0781],\n",
      "          [-0.1943,  0.0690,  0.1820, -0.0213,  0.0243],\n",
      "          [-0.1623, -0.0687,  0.0955, -0.0042,  0.1792],\n",
      "          [ 0.1982, -0.1160, -0.1037, -0.1599,  0.0861]]],\n",
      "\n",
      "\n",
      "        [[[-0.1396, -0.0177,  0.0515, -0.0642, -0.1050],\n",
      "          [-0.0027, -0.1556,  0.0639, -0.0471,  0.0611],\n",
      "          [-0.1123,  0.0749, -0.0442,  0.0948,  0.1336],\n",
      "          [-0.1880,  0.0703, -0.0063,  0.0069,  0.1250],\n",
      "          [-0.1163,  0.1312, -0.1258,  0.1402,  0.1669]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0656, -0.0911,  0.1968,  0.1829, -0.0063],\n",
      "          [ 0.0433,  0.0139, -0.0287, -0.0704,  0.1829],\n",
      "          [ 0.1850, -0.1535, -0.1039,  0.0234, -0.0951],\n",
      "          [ 0.1641,  0.1613,  0.0915, -0.0870,  0.1541],\n",
      "          [ 0.1128, -0.0999, -0.0630, -0.0908, -0.1714]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0763,  0.0678,  0.1757, -0.0266, -0.0277],\n",
      "          [-0.1385, -0.0997,  0.0775,  0.0288, -0.1490],\n",
      "          [ 0.1947, -0.0837,  0.0706,  0.0519,  0.1619],\n",
      "          [ 0.1861,  0.0660,  0.1805, -0.0352,  0.0150],\n",
      "          [-0.1358,  0.0664,  0.0470,  0.1817,  0.1585]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0622,  0.1118,  0.0846, -0.0102,  0.0897],\n",
      "          [-0.1453, -0.0695,  0.0290,  0.1203, -0.0758],\n",
      "          [-0.1541,  0.1100, -0.1442,  0.0534,  0.1055],\n",
      "          [-0.1888, -0.0212, -0.1472, -0.1542, -0.1080],\n",
      "          [-0.0664,  0.1987, -0.0143, -0.0747, -0.0917]]]])\n"
     ]
    }
   ],
   "source": [
    "print(net.conv1.weight )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
